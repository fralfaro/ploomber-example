{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Ploomber Example Docs!","text":"<p>Ploomber is a Python library designed to streamline the development and deployment of data pipelines. It allows you to build pipelines using your favorite editor (Jupyter Notebook, VS Code, etc.) and deploy them to various platforms like Kubernetes, Airflow, and the cloud (Ploomber Cloud) without requiring significant code changes.</p> <p>Here's a quick introduction to using Ploomber:</p> <p>1. Installation:</p> <p>Install Ploomber using pip:</p> <pre><code>pip install ploomber\n</code></pre> <p>2. Defining your pipeline:</p> <p>Ploomber lets you define your pipeline using either:</p> <ul> <li>Spec files (YAML): These files define the pipeline structure explicitly, specifying tasks, dependencies, and parameters.</li> <li>Jupyter Notebooks: You can use specially formatted Jupyter Notebooks where code cells are treated as pipeline tasks.</li> </ul> <p>3. Running the pipeline:</p> <p>Once you define your pipeline, you can run it locally using the <code>ploomber run</code> command. This executes the tasks in the defined order.</p> <p>4. Deployment:</p> <p>Ploomber shines in its deployment capabilities. You can push your code (including notebooks or spec files) to a Git repository like GitHub. Ploomber automatically detects the pipeline definition and deploys it to your chosen platform with minimal adjustments.</p> <p>Additional features:</p> <ul> <li>Parametrization: Easily manage pipeline configurations with parameters.</li> <li>Report generation: Generate reports automatically after pipeline execution.</li> <li>Integration with various tools: Works seamlessly with popular frameworks like TensorFlow, PyTorch, and scikit-learn.</li> </ul> <p>Getting started:</p> <p>Refer to the official Ploomber documentation https://docs.ploomber.io/ for detailed tutorials and examples to get you started with building and deploying your data pipelines.</p>"},{"location":"description/","title":"Description","text":""},{"location":"description/#the-challenge","title":"The Challenge","text":"<p>The sinking of the Titanic is one of the most infamous shipwrecks in history.</p> <p>On April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.</p> <p>While there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.</p> <p>In this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).</p>"},{"location":"description/#dataset-description","title":"Dataset Description","text":""},{"location":"description/#overview","title":"Overview","text":"<p>The data has been split into two groups:</p> <ul> <li>training set (<code>train.csv</code>)</li> <li>test set (<code>test.csv</code>)</li> </ul> <p>The training set should be used to build your machine learning models. For the training set, we provide the outcome (also known as the \u201cground truth\u201d) for each passenger. Your model will be based on \u201cfeatures\u201d like passengers\u2019 gender and class. You can also use feature engineering to create new features.</p> <p>The test set should be used to see how well your model performs on unseen data. For the test set, we do not provide the ground truth for each passenger. It is your job to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic.</p> <p>We also include gender_submission.csv, a set of predictions that assume all and only female passengers survive, as an example of what a submission file should look like.</p>"},{"location":"description/#data-dictionary","title":"Data Dictionary","text":"Variable Name Definition Possible Values <code>survival</code> Survival status 0 (No), 1 (Yes) <code>pclass</code> Passenger class 1 (1st), 2 (2nd), 3 (3rd) <code>sex</code> Gender Male, Female <code>age</code> Age in years Numerical <code>sibsp</code> Number of siblings/spouses on board Numerical <code>parch</code> Number of parents/children on board Numerical <code>ticket</code> Ticket number String <code>fare</code> Passenger fare Numerical <code>cabin</code> Cabin number String (may contain missing values) <code>embarked</code> Port of embarkation C (Cherbourg), Q (Queenstown), S (Southampton)"},{"location":"description/#variable-notes","title":"Variable Notes","text":"<p>pclass: A proxy for socio-economic status (SES)</p> <ul> <li>1st = Upper</li> <li>2nd = Middle</li> <li>3rd = Lower</li> </ul> <p>age: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5</p> <p>sibsp: The dataset defines family relations in this way...</p> <ul> <li>Sibling = brother, sister, stepbrother, stepsister</li> <li>Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)</li> </ul> <p>parch: The dataset defines family relations in this way... * Parent = mother, father * Child = daughter, son, stepdaughter, stepson * Some children travelled only with a nanny, therefore parch=0 for them.</p> <p>\ud83d\udd11 Note: For more details about the project, please see the Kaggle documentation on the Titanic challenge.</p>"}]}